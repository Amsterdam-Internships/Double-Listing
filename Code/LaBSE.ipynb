{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmJ_I6qxmbL0",
        "outputId": "9f92ceba-e5fb-4996-9281-31e1fb270803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1c-Tc9EVl2jN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertTokenizerFast\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3vGqoiW2z-I2"
      },
      "outputs": [],
      "source": [
        "df_extra = pd.read_csv('/content/descriptions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO18GTChlsK0",
        "outputId": "0c626c4f-738d-4327-a943-b96027d930fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "#This notebook is ran in Google Colab to use GPU for LaBSE embeddings\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3MTrzH_3mqGL"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
        "model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
        "model.cuda()\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "51RzKkuj0PVV"
      },
      "outputs": [],
      "source": [
        "def similarity(embeddings_1, embeddings_2):\n",
        "    normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
        "    normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    \n",
        "    return cos(embeddings_1, embeddings_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "lnnOAVIWnmmJ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A3L6SiN3o80D"
      },
      "outputs": [],
      "source": [
        "descriptions = list(df_extra['Description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrjB3Yni5CFq",
        "outputId": "dc81c8fc-3f10-4b32-877f-76e32b7b4a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 200\n",
            "200 400\n",
            "400 600\n",
            "600 800\n",
            "800 1000\n",
            "1000 1200\n",
            "1200 1400\n",
            "1400 1600\n",
            "1600 1800\n",
            "1800 2000\n",
            "2000 2200\n",
            "2200 2400\n",
            "2400 2600\n",
            "2600 2800\n",
            "2800 3000\n",
            "3000 3200\n",
            "3200 3400\n",
            "3400 3600\n",
            "3600 3800\n",
            "3800 4000\n",
            "4000 4200\n",
            "4200 4400\n",
            "4400 4600\n",
            "4600 4800\n",
            "4800 5000\n",
            "5000 5200\n"
          ]
        }
      ],
      "source": [
        "lista_tensors = []\n",
        "ln = 0\n",
        "rn = 200\n",
        "for i in range(26):\n",
        "  print(ln,rn)\n",
        "  torch.cuda.empty_cache()\n",
        "  if rn < 4672:\n",
        "    descriptions_1 = tokenizer(descriptions[ln:rn], return_tensors=\"pt\", padding=True, truncation=True,max_length=512)\n",
        "    descriptions_1.to(device)\n",
        "    with torch.no_grad():\n",
        "      descriptions_outputs = model(**descriptions_1)\n",
        "      lista_tensors.append(descriptions_outputs.pooler_output)\n",
        "  if rn > 4672 and ln <= 4672 :\n",
        "    descriptions_1 = tokenizer(descriptions[ln:4672], return_tensors=\"pt\", padding=True, truncation=True,max_length=512)\n",
        "    descriptions_1.to(device)\n",
        "    with torch.no_grad():\n",
        "      descriptions_outputs = model(**descriptions_1)\n",
        "      lista_tensors.append(descriptions_outputs.pooler_output)\n",
        "  \n",
        "  ln += 200\n",
        "  rn += 200\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HUw5CgZYpjUa"
      },
      "outputs": [],
      "source": [
        "final_tensor = torch.Tensor()\n",
        "for tensors in lista_tensors[:]:\n",
        "  final_tensor = torch.cat((final_tensor.to(device), tensors.to(device)), 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iRME1aMxp2GQ"
      },
      "outputs": [],
      "source": [
        "final_tensor = final_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qHvCISJNrAhe"
      },
      "outputs": [],
      "source": [
        "df_extra['LaBSE_emb'] = final_tensor.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ltdLVmamriEz"
      },
      "outputs": [],
      "source": [
        "df_extra.to_csv('df_extra_emb.csv',index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eFZR0MLSsFuW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "70QSMlTs8As6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LaBSE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
